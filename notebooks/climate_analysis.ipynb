{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66b90659",
   "metadata": {},
   "source": [
    "# ğŸŒ AnÃ¡lise ExploratÃ³ria de Dados ClimÃ¡ticos e Qualidade do Ar\n",
    "\n",
    "Este notebook apresenta uma anÃ¡lise completa de dados sobre mudanÃ§as climÃ¡ticas e qualidade do ar, incluindo:\n",
    "\n",
    "- **Coleta e preparaÃ§Ã£o de dados** de APIs meteorolÃ³gicas\n",
    "- **AnÃ¡lise exploratÃ³ria** com visualizaÃ§Ãµes interativas  \n",
    "- **Modelagem preditiva** usando Machine Learning\n",
    "- **Insights** sobre tendÃªncias climÃ¡ticas e qualidade do ar\n",
    "\n",
    "## Objetivos da AnÃ¡lise\n",
    "\n",
    "1. ğŸ“Š **Explorar padrÃµes** nos dados meteorolÃ³gicos histÃ³ricos\n",
    "2. ğŸŒ¡ï¸ **Identificar tendÃªncias** de temperatura e clima\n",
    "3. ğŸ’¨ **Analisar qualidade do ar** e seus fatores\n",
    "4. ğŸ¤– **Desenvolver modelos** para previsÃµes\n",
    "5. ğŸ“ˆ **Gerar insights** acionÃ¡veis para tomada de decisÃ£o\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8742f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "import sqlite3\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# ConfiguraÃ§Ãµes de visualizaÃ§Ã£o\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ConfiguraÃ§Ãµes do pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Adiciona o diretÃ³rio do projeto ao path\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "print(\"âœ… Bibliotecas importadas com sucesso!\")\n",
    "print(f\"ğŸ“Š Pandas: {pd.__version__}\")\n",
    "print(f\"ğŸ”¢ NumPy: {np.__version__}\")\n",
    "print(f\"ğŸ“ˆ Matplotlib: {plt.matplotlib.__version__}\")\n",
    "print(f\"ğŸ¨ Seaborn: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4fc21d",
   "metadata": {},
   "source": [
    "## ğŸ“ Load and Explore Dataset\n",
    "\n",
    "Nesta seÃ§Ã£o vamos carregar os dados coletados pelas APIs e realizar uma anÃ¡lise exploratÃ³ria inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a5241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados do banco SQLite\n",
    "def load_data_from_db(db_path='../data/climate_data.db'):\n",
    "    \"\"\"Carrega dados do banco SQLite\"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        \n",
    "        # Carrega dados meteorolÃ³gicos\n",
    "        weather_df = pd.read_sql_query(\"\"\"\n",
    "            SELECT * FROM weather_data \n",
    "            ORDER BY timestamp DESC\n",
    "        \"\"\", conn)\n",
    "        \n",
    "        # Carrega dados de qualidade do ar\n",
    "        air_quality_df = pd.read_sql_query(\"\"\"\n",
    "            SELECT * FROM air_quality_data \n",
    "            ORDER BY timestamp DESC\n",
    "        \"\"\", conn)\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        print(f\"âœ… Dados carregados com sucesso!\")\n",
    "        print(f\"ğŸ“Š Dados meteorolÃ³gicos: {len(weather_df)} registros\")\n",
    "        print(f\"ğŸ’¨ Dados de qualidade do ar: {len(air_quality_df)} registros\")\n",
    "        \n",
    "        return weather_df, air_quality_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro ao carregar dados: {e}\")\n",
    "        # Cria DataFrames vazios para demonstraÃ§Ã£o\n",
    "        weather_df = pd.DataFrame()\n",
    "        air_quality_df = pd.DataFrame()\n",
    "        \n",
    "        print(\"ğŸ“ Criando dados de exemplo para demonstraÃ§Ã£o...\")\n",
    "        # Dados de exemplo para demonstraÃ§Ã£o\n",
    "        dates = pd.date_range(start='2024-01-01', end='2024-12-31', freq='D')\n",
    "        \n",
    "        weather_df = pd.DataFrame({\n",
    "            'timestamp': dates,\n",
    "            'city': 'SÃ£o Paulo',\n",
    "            'country': 'BR',\n",
    "            'temperature': 20 + 10 * np.sin(np.arange(len(dates)) * 2 * np.pi / 365) + np.random.normal(0, 3, len(dates)),\n",
    "            'humidity': 60 + 20 * np.sin(np.arange(len(dates)) * 2 * np.pi / 365 + np.pi/4) + np.random.normal(0, 10, len(dates)),\n",
    "            'pressure': 1013 + np.random.normal(0, 15, len(dates)),\n",
    "            'wind_speed': 5 + np.random.exponential(3, len(dates))\n",
    "        })\n",
    "        \n",
    "        air_quality_df = pd.DataFrame({\n",
    "            'timestamp': dates[::3],  # Dados a cada 3 dias\n",
    "            'city': 'SÃ£o Paulo',\n",
    "            'country': 'BR',\n",
    "            'aqi_us': 50 + 30 * np.sin(np.arange(len(dates[::3])) * 2 * np.pi / 120) + np.random.normal(0, 15, len(dates[::3])),\n",
    "            'temperature': 20 + 10 * np.sin(np.arange(len(dates[::3])) * 2 * np.pi / 120) + np.random.normal(0, 3, len(dates[::3]))\n",
    "        })\n",
    "        \n",
    "        return weather_df, air_quality_df\n",
    "\n",
    "# Carregar os dados\n",
    "weather_data, air_quality_data = load_data_from_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c58a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnÃ¡lise exploratÃ³ria inicial dos dados meteorolÃ³gicos\n",
    "print(\"ğŸŒ¡ï¸ DADOS METEOROLÃ“GICOS - AnÃ¡lise Inicial\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if not weather_data.empty:\n",
    "    print(f\"ğŸ“Š Shape dos dados: {weather_data.shape}\")\n",
    "    print(f\"ğŸ“… PerÃ­odo: {weather_data['timestamp'].min()} atÃ© {weather_data['timestamp'].max()}\")\n",
    "    \n",
    "    # InformaÃ§Ãµes bÃ¡sicas\n",
    "    print(\"\\nğŸ“‹ InformaÃ§Ãµes Gerais:\")\n",
    "    print(weather_data.info())\n",
    "    \n",
    "    # Primeiras linhas\n",
    "    print(\"\\nğŸ‘€ Primeiras 5 linhas:\")\n",
    "    display(weather_data.head())\n",
    "    \n",
    "    # EstatÃ­sticas descritivas\n",
    "    print(\"\\nğŸ“ˆ EstatÃ­sticas Descritivas:\")\n",
    "    numeric_cols = weather_data.select_dtypes(include=[np.number]).columns\n",
    "    display(weather_data[numeric_cols].describe())\n",
    "    \n",
    "    # Verificar valores ausentes\n",
    "    print(\"\\nâ“ Valores Ausentes:\")\n",
    "    missing_data = weather_data.isnull().sum()\n",
    "    print(missing_data[missing_data > 0])\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ Nenhum dado meteorolÃ³gico encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4759748",
   "metadata": {},
   "source": [
    "## ğŸ”§ Data Preprocessing\n",
    "\n",
    "Vamos processar e limpar os dados para anÃ¡lise e modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f2f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrÃ©-processamento dos dados meteorolÃ³gicos\n",
    "def preprocess_weather_data(df):\n",
    "    \"\"\"Limpa e processa dados meteorolÃ³gicos\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    # Converter timestamp para datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df = df.sort_values('timestamp')\n",
    "    \n",
    "    # Adicionar features temporais\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['day'] = df['timestamp'].dt.day\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['day_of_year'] = df['timestamp'].dt.dayofyear\n",
    "    df['season'] = df['month'].map({12: 'VerÃ£o', 1: 'VerÃ£o', 2: 'VerÃ£o',\n",
    "                                   3: 'Outono', 4: 'Outono', 5: 'Outono',\n",
    "                                   6: 'Inverno', 7: 'Inverno', 8: 'Inverno',\n",
    "                                   9: 'Primavera', 10: 'Primavera', 11: 'Primavera'})\n",
    "    \n",
    "    # Limitar valores extremos (outliers)\n",
    "    numeric_cols = ['temperature', 'humidity', 'pressure', 'wind_speed']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            Q1 = df[col].quantile(0.01)\n",
    "            Q3 = df[col].quantile(0.99)\n",
    "            df[col] = df[col].clip(lower=Q1, upper=Q3)\n",
    "    \n",
    "    # Interpolar valores ausentes\n",
    "    df[numeric_cols] = df[numeric_cols].interpolate(method='time')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Aplicar prÃ©-processamento\n",
    "weather_processed = preprocess_weather_data(weather_data.copy())\n",
    "print(\"âœ… Dados meteorolÃ³gicos processados!\")\n",
    "\n",
    "if not weather_processed.empty:\n",
    "    print(f\"ğŸ“Š Shape apÃ³s processamento: {weather_processed.shape}\")\n",
    "    print(f\"ğŸ“… PerÃ­odo: {weather_processed['timestamp'].min()} atÃ© {weather_processed['timestamp'].max()}\")\n",
    "    \n",
    "    # Verificar valores ausentes apÃ³s processamento\n",
    "    missing_after = weather_processed.isnull().sum()\n",
    "    print(f\"\\nâ“ Valores ausentes apÃ³s processamento:\")\n",
    "    print(missing_after[missing_after > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cc4801",
   "metadata": {},
   "source": [
    "## âš™ï¸ Feature Engineering\n",
    "\n",
    "CriaÃ§Ã£o de novas features para melhorar o desempenho dos modelos de ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aaedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering para dados climÃ¡ticos\n",
    "def create_climate_features(df):\n",
    "    \"\"\"Cria features avanÃ§adas para anÃ¡lise climÃ¡tica\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Features de conforto tÃ©rmico\n",
    "    if 'temperature' in df.columns and 'humidity' in df.columns:\n",
    "        # Ãndice de calor (sensaÃ§Ã£o tÃ©rmica)\n",
    "        df['heat_index'] = df['temperature'] + 0.5 * (df['humidity'] / 100) * (df['temperature'] - 14.5)\n",
    "        \n",
    "        # ClassificaÃ§Ã£o de conforto\n",
    "        df['comfort_level'] = pd.cut(df['heat_index'], \n",
    "                                   bins=[-np.inf, 15, 25, 30, 35, np.inf],\n",
    "                                   labels=['Frio', 'ConfortÃ¡vel', 'Quente', 'Muito Quente', 'Extremo'])\n",
    "    \n",
    "    # Features temporais avanÃ§adas\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        \n",
    "        # Ciclos trigonomÃ©tricos para capturar sazonalidade\n",
    "        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "        df['day_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "        df['day_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "        \n",
    "        # Features de tendÃªncia\n",
    "        df['temp_ma_7'] = df['temperature'].rolling(window=7, center=True).mean()\n",
    "        df['temp_std_7'] = df['temperature'].rolling(window=7, center=True).std()\n",
    "        \n",
    "        # DetecÃ§Ã£o de anomalias simples\n",
    "        df['temp_zscore'] = (df['temperature'] - df['temperature'].mean()) / df['temperature'].std()\n",
    "        df['is_anomaly'] = np.abs(df['temp_zscore']) > 2\n",
    "    \n",
    "    # Features de vento\n",
    "    if 'wind_speed' in df.columns:\n",
    "        df['wind_category'] = pd.cut(df['wind_speed'],\n",
    "                                   bins=[0, 2, 5, 10, 15, np.inf],\n",
    "                                   labels=['Calmo', 'Brisa Leve', 'Brisa Moderada', 'Vento Forte', 'Ventania'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Aplicar feature engineering\n",
    "weather_featured = create_climate_features(weather_processed)\n",
    "\n",
    "print(\"âœ… Feature engineering concluÃ­da!\")\n",
    "print(f\"ğŸ“Š Novas features criadas:\")\n",
    "new_cols = set(weather_featured.columns) - set(weather_processed.columns)\n",
    "for col in new_cols:\n",
    "    print(f\"   â€¢ {col}\")\n",
    "\n",
    "# Visualizar correlaÃ§Ãµes das novas features\n",
    "if not weather_featured.empty:\n",
    "    numeric_features = weather_featured.select_dtypes(include=[np.number]).columns\n",
    "    correlation_matrix = weather_featured[numeric_features].corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "    plt.title('ğŸ”— Matriz de CorrelaÃ§Ã£o - Features ClimÃ¡ticas')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4ff072",
   "metadata": {},
   "source": [
    "## ğŸ¤– Model Training\n",
    "\n",
    "Treinamento de modelos de Machine Learning para previsÃ£o de temperatura e classificaÃ§Ã£o de conforto tÃ©rmico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b32cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning para previsÃ£o climÃ¡tica\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "def prepare_ml_data(df):\n",
    "    \"\"\"Prepara dados para machine learning\"\"\"\n",
    "    if df.empty:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Features para o modelo\n",
    "    feature_cols = ['month', 'day_of_year', 'humidity', 'pressure', 'wind_speed',\n",
    "                   'month_sin', 'month_cos', 'day_sin', 'day_cos']\n",
    "    \n",
    "    # Filtrar apenas colunas que existem\n",
    "    available_features = [col for col in feature_cols if col in df.columns]\n",
    "    \n",
    "    if len(available_features) < 3:\n",
    "        print(\"âš ï¸ NÃ£o hÃ¡ features suficientes para treinamento\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Preparar dados\n",
    "    X = df[available_features].dropna()\n",
    "    y_temp = df.loc[X.index, 'temperature']\n",
    "    \n",
    "    # Para classificaÃ§Ã£o de conforto (se disponÃ­vel)\n",
    "    y_comfort = None\n",
    "    if 'comfort_level' in df.columns:\n",
    "        y_comfort = df.loc[X.index, 'comfort_level'].dropna()\n",
    "        # Alinhar Ã­ndices\n",
    "        common_idx = X.index.intersection(y_comfort.index)\n",
    "        X_comfort = X.loc[common_idx]\n",
    "        y_comfort = y_comfort.loc[common_idx]\n",
    "    else:\n",
    "        X_comfort = None\n",
    "    \n",
    "    return X, y_temp, X_comfort, y_comfort\n",
    "\n",
    "# Preparar dados\n",
    "X, y_temp, X_comfort, y_comfort = prepare_ml_data(weather_featured)\n",
    "\n",
    "if X is not None and len(X) > 10:\n",
    "    print(\"âœ… Dados preparados para ML!\")\n",
    "    print(f\"ğŸ“Š Features disponÃ­veis: {list(X.columns)}\")\n",
    "    print(f\"ğŸ“ˆ Amostras para treinamento: {len(X)}\")\n",
    "    \n",
    "    # Dividir dados\n",
    "    X_train, X_test, y_train_temp, y_test_temp = train_test_split(\n",
    "        X, y_temp, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Modelo 1: RegressÃ£o para temperatura\n",
    "    print(\"\\nğŸŒ¡ï¸ Treinando modelo de previsÃ£o de temperatura...\")\n",
    "    temp_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    temp_model.fit(X_train, y_train_temp)\n",
    "    \n",
    "    # PrevisÃµes\n",
    "    y_pred_temp = temp_model.predict(X_test)\n",
    "    \n",
    "    # MÃ©tricas\n",
    "    mse = mean_squared_error(y_test_temp, y_pred_temp)\n",
    "    r2 = r2_score(y_test_temp, y_pred_temp)\n",
    "    \n",
    "    print(f\"ğŸ“Š MÃ©tricas do modelo de temperatura:\")\n",
    "    print(f\"   â€¢ MSE: {mse:.2f}\")\n",
    "    print(f\"   â€¢ RÂ²: {r2:.3f}\")\n",
    "    print(f\"   â€¢ RMSE: {np.sqrt(mse):.2f}Â°C\")\n",
    "    \n",
    "    # ImportÃ¢ncia das features\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': temp_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nğŸ¯ ImportÃ¢ncia das Features:\")\n",
    "    for _, row in feature_importance.head().iterrows():\n",
    "        print(f\"   â€¢ {row['feature']}: {row['importance']:.3f}\")\n",
    "    \n",
    "    # Modelo 2: ClassificaÃ§Ã£o de conforto (se disponÃ­vel)\n",
    "    if X_comfort is not None and len(X_comfort) > 10:\n",
    "        print(\"\\nğŸ  Treinando modelo de classificaÃ§Ã£o de conforto...\")\n",
    "        \n",
    "        # Preparar dados de classificaÃ§Ã£o\n",
    "        X_train_comfort, X_test_comfort, y_train_comfort, y_test_comfort = train_test_split(\n",
    "            X_comfort, y_comfort, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Encoder para labels\n",
    "        le = LabelEncoder()\n",
    "        y_train_comfort_encoded = le.fit_transform(y_train_comfort)\n",
    "        y_test_comfort_encoded = le.transform(y_test_comfort)\n",
    "        \n",
    "        # Modelo\n",
    "        comfort_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        comfort_model.fit(X_train_comfort, y_train_comfort_encoded)\n",
    "        \n",
    "        # PrevisÃµes\n",
    "        y_pred_comfort = comfort_model.predict(X_test_comfort)\n",
    "        \n",
    "        # RelatÃ³rio de classificaÃ§Ã£o\n",
    "        print(\"ğŸ“Š RelatÃ³rio de ClassificaÃ§Ã£o de Conforto:\")\n",
    "        print(classification_report(y_test_comfort_encoded, y_pred_comfort, \n",
    "                                  target_names=le.classes_))\n",
    "        \n",
    "        # Salvar modelos\n",
    "        joblib.dump(temp_model, '../data/temperature_model.pkl')\n",
    "        joblib.dump(comfort_model, '../data/comfort_model.pkl')\n",
    "        joblib.dump(le, '../data/comfort_encoder.pkl')\n",
    "        print(\"\\nğŸ’¾ Modelos salvos com sucesso!\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ Dados insuficientes para treinamento de ML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ab74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnÃ¡lise exploratÃ³ria dos dados de qualidade do ar\n",
    "print(\"\\nğŸ’¨ DADOS DE QUALIDADE DO AR - AnÃ¡lise Inicial\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if not air_quality_data.empty:\n",
    "    print(f\"ğŸ“Š Shape dos dados: {air_quality_data.shape}\")\n",
    "    \n",
    "    # InformaÃ§Ãµes bÃ¡sicas\n",
    "    print(\"\\nğŸ“‹ InformaÃ§Ãµes Gerais:\")\n",
    "    print(air_quality_data.info())\n",
    "    \n",
    "    # Primeiras linhas\n",
    "    print(\"\\nğŸ‘€ Primeiras 5 linhas:\")\n",
    "    display(air_quality_data.head())\n",
    "    \n",
    "    # EstatÃ­sticas descritivas\n",
    "    print(\"\\nğŸ“ˆ EstatÃ­sticas Descritivas:\")\n",
    "    numeric_cols = air_quality_data.select_dtypes(include=[np.number]).columns\n",
    "    display(air_quality_data[numeric_cols].describe())\n",
    "    \n",
    "    # DistribuiÃ§Ã£o de AQI\n",
    "    if 'aqi_us' in air_quality_data.columns:\n",
    "        print(f\"\\nğŸ¯ AQI MÃ©dio: {air_quality_data['aqi_us'].mean():.1f}\")\n",
    "        print(f\"ğŸ“Š AQI MÃ­nimo: {air_quality_data['aqi_us'].min():.1f}\")\n",
    "        print(f\"ğŸ“Š AQI MÃ¡ximo: {air_quality_data['aqi_us'].max():.1f}\")\n",
    "        \n",
    "        # Categorias de qualidade do ar\n",
    "        def categorize_aqi(aqi):\n",
    "            if aqi <= 50: return \"Boa\"\n",
    "            elif aqi <= 100: return \"Moderada\"\n",
    "            elif aqi <= 150: return \"Insalubre (Grupos SensÃ­veis)\"\n",
    "            elif aqi <= 200: return \"Insalubre\"\n",
    "            elif aqi <= 300: return \"Muito Insalubre\"\n",
    "            else: return \"Perigosa\"\n",
    "        \n",
    "        air_quality_data['aqi_category'] = air_quality_data['aqi_us'].apply(categorize_aqi)\n",
    "        print(\"\\nğŸ·ï¸ DistribuiÃ§Ã£o por Categoria:\")\n",
    "        print(air_quality_data['aqi_category'].value_counts())\n",
    "        \n",
    "else:\n",
    "    print(\"âš ï¸ Nenhum dado de qualidade do ar encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9daa3",
   "metadata": {},
   "source": [
    "## ğŸ”§ Data Preprocessing\n",
    "\n",
    "Nesta seÃ§Ã£o vamos limpar e preparar os dados para anÃ¡lise, incluindo tratamento de valores ausentes, conversÃ£o de tipos e padronizaÃ§Ã£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunÃ§Ã£o para preprocessar dados meteorolÃ³gicos\n",
    "def preprocess_weather_data(df):\n",
    "    \"\"\"Preprocessa dados meteorolÃ³gicos\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    # Copia para nÃ£o modificar o original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Converte timestamp para datetime\n",
    "    if 'timestamp' in df_clean.columns:\n",
    "        df_clean['timestamp'] = pd.to_datetime(df_clean['timestamp'])\n",
    "        df_clean = df_clean.sort_values('timestamp')\n",
    "    \n",
    "    # Remove outliers extremos (mÃ©todo IQR)\n",
    "    numeric_columns = ['temperature', 'humidity', 'pressure', 'wind_speed']\n",
    "    for col in numeric_columns:\n",
    "        if col in df_clean.columns:\n",
    "            Q1 = df_clean[col].quantile(0.25)\n",
    "            Q3 = df_clean[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            outliers_before = len(df_clean[(df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)])\n",
    "            df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "            \n",
    "            if outliers_before > 0:\n",
    "                print(f\"ğŸ§¹ {col}: Removidos {outliers_before} outliers\")\n",
    "    \n",
    "    # Preenche valores ausentes com interpolaÃ§Ã£o\n",
    "    for col in numeric_columns:\n",
    "        if col in df_clean.columns:\n",
    "            missing_before = df_clean[col].isnull().sum()\n",
    "            if missing_before > 0:\n",
    "                df_clean[col] = df_clean[col].interpolate(method='linear')\n",
    "                print(f\"ğŸ”§ {col}: Preenchidos {missing_before} valores ausentes\")\n",
    "    \n",
    "    # Adiciona features temporais\n",
    "    if 'timestamp' in df_clean.columns:\n",
    "        df_clean['hour'] = df_clean['timestamp'].dt.hour\n",
    "        df_clean['day_of_week'] = df_clean['timestamp'].dt.dayofweek\n",
    "        df_clean['month'] = df_clean['timestamp'].dt.month\n",
    "        df_clean['season'] = df_clean['month'].apply(lambda x: \n",
    "            'VerÃ£o' if x in [12, 1, 2] else\n",
    "            'Outono' if x in [3, 4, 5] else\n",
    "            'Inverno' if x in [6, 7, 8] else 'Primavera'\n",
    "        )\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# FunÃ§Ã£o para preprocessar dados de qualidade do ar\n",
    "def preprocess_air_quality_data(df):\n",
    "    \"\"\"Preprocessa dados de qualidade do ar\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    # Copia para nÃ£o modificar o original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Converte timestamp para datetime\n",
    "    if 'timestamp' in df_clean.columns:\n",
    "        df_clean['timestamp'] = pd.to_datetime(df_clean['timestamp'])\n",
    "        df_clean = df_clean.sort_values('timestamp')\n",
    "    \n",
    "    # Limita AQI a valores vÃ¡lidos (0-500)\n",
    "    if 'aqi_us' in df_clean.columns:\n",
    "        df_clean = df_clean[(df_clean['aqi_us'] >= 0) & (df_clean['aqi_us'] <= 500)]\n",
    "    \n",
    "    # Adiciona categorias de qualidade do ar\n",
    "    if 'aqi_us' in df_clean.columns:\n",
    "        def categorize_aqi(aqi):\n",
    "            if aqi <= 50: return \"Boa\"\n",
    "            elif aqi <= 100: return \"Moderada\"\n",
    "            elif aqi <= 150: return \"Insalubre (Grupos SensÃ­veis)\"\n",
    "            elif aqi <= 200: return \"Insalubre\"\n",
    "            elif aqi <= 300: return \"Muito Insalubre\"\n",
    "            else: return \"Perigosa\"\n",
    "        \n",
    "        df_clean['aqi_category'] = df_clean['aqi_us'].apply(categorize_aqi)\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Aplicar preprocessamento\n",
    "print(\"ğŸ”§ Iniciando preprocessamento dos dados...\")\n",
    "\n",
    "weather_clean = preprocess_weather_data(weather_data)\n",
    "air_quality_clean = preprocess_air_quality_data(air_quality_data)\n",
    "\n",
    "print(f\"\\nâœ… Preprocessamento concluÃ­do!\")\n",
    "print(f\"ğŸ“Š Dados meteorolÃ³gicos: {len(weather_clean)} registros limpos\")\n",
    "print(f\"ğŸ’¨ Dados de qualidade do ar: {len(air_quality_clean)} registros limpos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29479817",
   "metadata": {},
   "source": [
    "## âš™ï¸ Feature Engineering\n",
    "\n",
    "Vamos criar novas features que podem ser Ãºteis para anÃ¡lise e modelagem, incluindo Ã­ndices compostos e caracterÃ­sticas temporais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0566a99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering para dados meteorolÃ³gicos\n",
    "def create_weather_features(df):\n",
    "    \"\"\"Cria features derivadas para dados meteorolÃ³gicos\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    df_features = df.copy()\n",
    "    \n",
    "    # Ãndice de desconforto tÃ©rmico (Heat Index)\n",
    "    if 'temperature' in df_features.columns and 'humidity' in df_features.columns:\n",
    "        T = df_features['temperature']\n",
    "        H = df_features['humidity']\n",
    "        \n",
    "        # FÃ³rmula simplificada do Heat Index\n",
    "        df_features['heat_index'] = T + 0.5 * (T + 61.0) + ((T - 68.0) * 1.2) + (H * 0.094)\n",
    "        \n",
    "        # Categoria de conforto tÃ©rmico\n",
    "        def comfort_category(heat_index):\n",
    "            if heat_index < 21: return \"Frio\"\n",
    "            elif heat_index < 27: return \"ConfortÃ¡vel\"\n",
    "            elif heat_index < 32: return \"Quente\"\n",
    "            else: return \"Muito Quente\"\n",
    "        \n",
    "        df_features['comfort_level'] = df_features['heat_index'].apply(comfort_category)\n",
    "    \n",
    "    # Ãndice de vento (Wind Chill)\n",
    "    if 'temperature' in df_features.columns and 'wind_speed' in df_features.columns:\n",
    "        T = df_features['temperature']\n",
    "        V = df_features['wind_speed'] * 3.6  # Converte m/s para km/h\n",
    "        \n",
    "        # Wind Chill para temperaturas baixas\n",
    "        df_features['wind_chill'] = np.where(\n",
    "            (T < 10) & (V > 4.8),\n",
    "            13.12 + 0.6215 * T - 11.37 * (V ** 0.16) + 0.3965 * T * (V ** 0.16),\n",
    "            T\n",
    "        )\n",
    "    \n",
    "    # PressÃ£o normalizada (diferenÃ§a da pressÃ£o padrÃ£o)\n",
    "    if 'pressure' in df_features.columns:\n",
    "        df_features['pressure_anomaly'] = df_features['pressure'] - 1013.25\n",
    "        \n",
    "        # TendÃªncia de pressÃ£o (diferenÃ§a com valor anterior)\n",
    "        df_features['pressure_trend'] = df_features['pressure'].diff()\n",
    "    \n",
    "    # Features de rolagem (mÃ©dias mÃ³veis)\n",
    "    if 'temperature' in df_features.columns:\n",
    "        df_features['temp_ma_3d'] = df_features['temperature'].rolling(window=3, min_periods=1).mean()\n",
    "        df_features['temp_ma_7d'] = df_features['temperature'].rolling(window=7, min_periods=1).mean()\n",
    "    \n",
    "    # Variabilidade (desvio padrÃ£o mÃ³vel)\n",
    "    if 'temperature' in df_features.columns:\n",
    "        df_features['temp_volatility'] = df_features['temperature'].rolling(window=7, min_periods=1).std()\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "# Feature Engineering para dados de qualidade do ar\n",
    "def create_air_quality_features(df):\n",
    "    \"\"\"Cria features derivadas para dados de qualidade do ar\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    df_features = df.copy()\n",
    "    \n",
    "    # Ãndice de risco Ã  saÃºde baseado no AQI\n",
    "    if 'aqi_us' in df_features.columns:\n",
    "        def health_risk_score(aqi):\n",
    "            if aqi <= 50: return 1  # Baixo risco\n",
    "            elif aqi <= 100: return 2  # Risco moderado\n",
    "            elif aqi <= 150: return 3  # Risco alto para sensÃ­veis\n",
    "            elif aqi <= 200: return 4  # Risco alto\n",
    "            elif aqi <= 300: return 5  # Risco muito alto\n",
    "            else: return 6  # Risco extremo\n",
    "        \n",
    "        df_features['health_risk'] = df_features['aqi_us'].apply(health_risk_score)\n",
    "        \n",
    "        # TendÃªncia do AQI\n",
    "        df_features['aqi_trend'] = df_features['aqi_us'].diff()\n",
    "        \n",
    "        # MÃ©dia mÃ³vel do AQI\n",
    "        df_features['aqi_ma_3d'] = df_features['aqi_us'].rolling(window=3, min_periods=1).mean()\n",
    "        df_features['aqi_ma_7d'] = df_features['aqi_us'].rolling(window=7, min_periods=1).mean()\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "# Aplicar feature engineering\n",
    "print(\"âš™ï¸ Criando features derivadas...\")\n",
    "\n",
    "if not weather_clean.empty:\n",
    "    weather_with_features = create_weather_features(weather_clean)\n",
    "    print(f\"ğŸŒ¡ï¸ Features meteorolÃ³gicas criadas: {weather_with_features.shape[1]} colunas\")\n",
    "    \n",
    "    # Mostra as novas features\n",
    "    new_weather_cols = set(weather_with_features.columns) - set(weather_clean.columns)\n",
    "    print(f\"   Novas features: {list(new_weather_cols)}\")\n",
    "\n",
    "if not air_quality_clean.empty:\n",
    "    air_quality_with_features = create_air_quality_features(air_quality_clean)\n",
    "    print(f\"ğŸ’¨ Features de qualidade do ar criadas: {air_quality_with_features.shape[1]} colunas\")\n",
    "    \n",
    "    # Mostra as novas features\n",
    "    new_air_cols = set(air_quality_with_features.columns) - set(air_quality_clean.columns)\n",
    "    print(f\"   Novas features: {list(new_air_cols)}\")\n",
    "\n",
    "print(\"\\nâœ… Feature engineering concluÃ­do!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0824881",
   "metadata": {},
   "source": [
    "## ğŸ¤– Model Training\n",
    "\n",
    "Vamos treinar modelos de Machine Learning para prever a qualidade do ar baseado em condiÃ§Ãµes meteorolÃ³gicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas de ML\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "# Preparar dados para modelagem (exemplo: prever AQI baseado em dados meteorolÃ³gicos)\n",
    "def prepare_ml_data():\n",
    "    \"\"\"Prepara dados para machine learning\"\"\"\n",
    "    \n",
    "    # Criar dataset simulado para demonstraÃ§Ã£o se nÃ£o houver dados reais\n",
    "    if weather_clean.empty or air_quality_clean.empty:\n",
    "        print(\"ğŸ“ Criando dataset simulado para demonstraÃ§Ã£o...\")\n",
    "        \n",
    "        # Dataset sintÃ©tico para demonstraÃ§Ã£o\n",
    "        np.random.seed(42)\n",
    "        n_samples = 1000\n",
    "        \n",
    "        # Features meteorolÃ³gicas\n",
    "        temperature = np.random.normal(25, 10, n_samples)\n",
    "        humidity = np.random.normal(60, 20, n_samples)\n",
    "        pressure = np.random.normal(1013, 15, n_samples)\n",
    "        wind_speed = np.random.exponential(5, n_samples)\n",
    "        \n",
    "        # Target: AQI influenciado pelas condiÃ§Ãµes meteorolÃ³gicas\n",
    "        # AQI aumenta com temperatura alta, humidade baixa e vento baixo\n",
    "        aqi = (\n",
    "            50 +  # Base\n",
    "            (temperature - 25) * 1.5 +  # Temperatura\n",
    "            (60 - humidity) * 0.8 +     # Humidade (inversa)\n",
    "            (5 - wind_speed) * 2 +      # Vento (inverso)\n",
    "            np.random.normal(0, 15, n_samples)  # RuÃ­do\n",
    "        )\n",
    "        aqi = np.clip(aqi, 0, 300)  # Limita AQI a valores vÃ¡lidos\n",
    "        \n",
    "        ml_data = pd.DataFrame({\n",
    "            'temperature': temperature,\n",
    "            'humidity': humidity,\n",
    "            'pressure': pressure,\n",
    "            'wind_speed': wind_speed,\n",
    "            'aqi_us': aqi\n",
    "        })\n",
    "        \n",
    "        # Adicionar features derivadas\n",
    "        ml_data['heat_index'] = ml_data['temperature'] + 0.5 * ml_data['humidity']\n",
    "        ml_data['pressure_anomaly'] = ml_data['pressure'] - 1013\n",
    "        \n",
    "    else:\n",
    "        # Usar dados reais se disponÃ­veis\n",
    "        print(\"ğŸ“Š Usando dados reais para modelagem...\")\n",
    "        # Combinar dados meteorolÃ³gicos e de qualidade do ar por timestamp\n",
    "        ml_data = pd.merge(weather_with_features, air_quality_with_features, \n",
    "                          on='timestamp', how='inner', suffixes=('_weather', '_air'))\n",
    "    \n",
    "    return ml_data\n",
    "\n",
    "# Preparar dados\n",
    "ml_dataset = prepare_ml_data()\n",
    "print(f\"ğŸ“Š Dataset para ML: {ml_dataset.shape}\")\n",
    "print(f\"ğŸ¯ Target: AQI (qualidade do ar)\")\n",
    "\n",
    "# Definir features e target\n",
    "feature_columns = ['temperature', 'humidity', 'pressure', 'wind_speed', 'heat_index', 'pressure_anomaly']\n",
    "target_column = 'aqi_us'\n",
    "\n",
    "# Verificar se as colunas existem\n",
    "available_features = [col for col in feature_columns if col in ml_dataset.columns]\n",
    "print(f\"ğŸ”§ Features disponÃ­veis: {available_features}\")\n",
    "\n",
    "if target_column in ml_dataset.columns and len(available_features) > 0:\n",
    "    X = ml_dataset[available_features]\n",
    "    y = ml_dataset[target_column]\n",
    "    \n",
    "    # Remover valores ausentes\n",
    "    mask = ~(X.isnull().any(axis=1) | y.isnull())\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    \n",
    "    print(f\"âœ… Dados preparados: {X.shape[0]} amostras, {X.shape[1]} features\")\n",
    "    \n",
    "    # Dividir em treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Normalizar features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print(f\"ğŸ”„ Train set: {X_train.shape[0]} amostras\")\n",
    "    print(f\"ğŸ”„ Test set: {X_test.shape[0]} amostras\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ NÃ£o foi possÃ­vel preparar dados para ML\")\n",
    "    X_train = X_test = y_train = y_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4300459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar mÃºltiplos modelos\n",
    "if X_train is not None:\n",
    "    print(\"ğŸš€ Iniciando treinamento de modelos...\")\n",
    "    \n",
    "    # DicionÃ¡rio de modelos\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Treinar e avaliar cada modelo\n",
    "    model_results = {}\n",
    "    trained_models = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nğŸ”„ Treinando {name}...\")\n",
    "        \n",
    "        # Treinar modelo\n",
    "        if name == 'Linear Regression':\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calcular mÃ©tricas\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # ValidaÃ§Ã£o cruzada\n",
    "        if name == 'Linear Regression':\n",
    "            cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "        else:\n",
    "            cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        model_results[name] = {\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'RÂ²': r2,\n",
    "            'CV RÂ² Mean': cv_scores.mean(),\n",
    "            'CV RÂ² Std': cv_scores.std()\n",
    "        }\n",
    "        \n",
    "        trained_models[name] = model\n",
    "        \n",
    "        print(f\"   RMSE: {rmse:.2f}\")\n",
    "        print(f\"   MAE: {mae:.2f}\")\n",
    "        print(f\"   RÂ²: {r2:.3f}\")\n",
    "        print(f\"   CV RÂ² (mean Â± std): {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}\")\n",
    "    \n",
    "    # Resumo dos resultados\n",
    "    print(\"\\nğŸ“Š RESUMO DOS MODELOS\")\n",
    "    print(\"=\" * 60)\n",
    "    results_df = pd.DataFrame(model_results).T\n",
    "    display(results_df.round(3))\n",
    "    \n",
    "    # Selecionar melhor modelo\n",
    "    best_model_name = results_df['RÂ²'].idxmax()\n",
    "    best_model = trained_models[best_model_name]\n",
    "    \n",
    "    print(f\"\\nğŸ† Melhor modelo: {best_model_name}\")\n",
    "    print(f\"   RÂ² Score: {results_df.loc[best_model_name, 'RÂ²']:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ NÃ£o foi possÃ­vel treinar modelos devido Ã  falta de dados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee5693a",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Model Evaluation\n",
    "\n",
    "Vamos avaliar o desempenho dos modelos treinados com visualizaÃ§Ãµes e mÃ©tricas detalhadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae76d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VisualizaÃ§Ãµes de avaliaÃ§Ã£o dos modelos\n",
    "if X_train is not None and 'best_model' in locals():\n",
    "    \n",
    "    # Fazer previsÃµes com o melhor modelo\n",
    "    if best_model_name == 'Linear Regression':\n",
    "        y_pred_best = best_model.predict(X_test_scaled)\n",
    "        y_train_pred = best_model.predict(X_train_scaled)\n",
    "    else:\n",
    "        y_pred_best = best_model.predict(X_test)\n",
    "        y_train_pred = best_model.predict(X_train)\n",
    "    \n",
    "    # Criar subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=[\n",
    "            'Valores Reais vs Preditos',\n",
    "            'DistribuiÃ§Ã£o dos ResÃ­duos',\n",
    "            'ImportÃ¢ncia das Features',\n",
    "            'ComparaÃ§Ã£o de Modelos'\n",
    "        ],\n",
    "        specs=[[{\"type\": \"scatter\"}, {\"type\": \"histogram\"}],\n",
    "               [{\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Scatter plot: Valores reais vs preditos\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=y_test, \n",
    "            y=y_pred_best,\n",
    "            mode='markers',\n",
    "            name='Teste',\n",
    "            marker=dict(color='blue', opacity=0.6)\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Linha diagonal (prediÃ§Ã£o perfeita)\n",
    "    min_val = min(y_test.min(), y_pred_best.min())\n",
    "    max_val = max(y_test.max(), y_pred_best.max())\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[min_val, max_val],\n",
    "            y=[min_val, max_val],\n",
    "            mode='lines',\n",
    "            name='PrediÃ§Ã£o Perfeita',\n",
    "            line=dict(color='red', dash='dash')\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Histograma dos resÃ­duos\n",
    "    residuals = y_test - y_pred_best\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=residuals,\n",
    "            name='ResÃ­duos',\n",
    "            nbinsx=30,\n",
    "            marker=dict(color='lightblue')\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. ImportÃ¢ncia das features (se disponÃ­vel)\n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': available_features,\n",
    "            'importance': best_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=True)\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=feature_importance['importance'],\n",
    "                y=feature_importance['feature'],\n",
    "                orientation='h',\n",
    "                name='ImportÃ¢ncia',\n",
    "                marker=dict(color='green')\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    # 4. ComparaÃ§Ã£o de modelos\n",
    "    model_names = list(model_results.keys())\n",
    "    r2_scores = [model_results[name]['RÂ²'] for name in model_names]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=model_names,\n",
    "            y=r2_scores,\n",
    "            name='RÂ² Score',\n",
    "            marker=dict(color=['red' if name == best_model_name else 'lightblue' for name in model_names])\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Atualizar layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title_text=\"AvaliaÃ§Ã£o dos Modelos de PrediÃ§Ã£o de AQI\",\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # Atualizar eixos\n",
    "    fig.update_xaxes(title_text=\"AQI Real\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"AQI Predito\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"ResÃ­duos\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"FrequÃªncia\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"ImportÃ¢ncia\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Modelo\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"RÂ² Score\", row=2, col=2)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # EstatÃ­sticas detalhadas dos resÃ­duos\n",
    "    print(\"ğŸ“Š ANÃLISE DOS RESÃDUOS\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"MÃ©dia dos resÃ­duos: {residuals.mean():.3f}\")\n",
    "    print(f\"Desvio padrÃ£o: {residuals.std():.3f}\")\n",
    "    print(f\"ResÃ­duo mÃ­nimo: {residuals.min():.3f}\")\n",
    "    print(f\"ResÃ­duo mÃ¡ximo: {residuals.max():.3f}\")\n",
    "    \n",
    "    # Teste de normalidade dos resÃ­duos (visual)\n",
    "    from scipy import stats\n",
    "    _, p_value = stats.normaltest(residuals)\n",
    "    print(f\"Teste de normalidade (p-value): {p_value:.3f}\")\n",
    "    \n",
    "    if p_value > 0.05:\n",
    "        print(\"âœ… ResÃ­duos seguem distribuiÃ§Ã£o normal (p > 0.05)\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ResÃ­duos nÃ£o seguem distribuiÃ§Ã£o normal (p â‰¤ 0.05)\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ NÃ£o foi possÃ­vel avaliar modelos devido Ã  falta de dados ou treinamento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5d2026",
   "metadata": {},
   "source": [
    "## ğŸ”® Make Predictions\n",
    "\n",
    "Vamos usar o modelo treinado para fazer previsÃµes em cenÃ¡rios hipotÃ©ticos e interpretar os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c47f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsÃµes em cenÃ¡rios hipotÃ©ticos\n",
    "if X_train is not None and 'best_model' in locals():\n",
    "    \n",
    "    print(\"ğŸ”® ANÃLISE DE CENÃRIOS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Definir cenÃ¡rios de teste\n",
    "    scenarios = {\n",
    "        'Dia TÃ­pico de VerÃ£o': {\n",
    "            'temperature': 32,\n",
    "            'humidity': 45,\n",
    "            'pressure': 1015,\n",
    "            'wind_speed': 3,\n",
    "        },\n",
    "        'Dia Frio de Inverno': {\n",
    "            'temperature': 15,\n",
    "            'humidity': 80,\n",
    "            'pressure': 1020,\n",
    "            'wind_speed': 8,\n",
    "        },\n",
    "        'Dia Quente e Ãšmido': {\n",
    "            'temperature': 35,\n",
    "            'humidity': 85,\n",
    "            'pressure': 1008,\n",
    "            'wind_speed': 2,\n",
    "        },\n",
    "        'CondiÃ§Ãµes Ideais': {\n",
    "            'temperature': 24,\n",
    "            'humidity': 60,\n",
    "            'pressure': 1013,\n",
    "            'wind_speed': 10,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # FunÃ§Ã£o para criar features derivadas\n",
    "    def create_scenario_features(temp, humidity, pressure, wind_speed):\n",
    "        features = {\n",
    "            'temperature': temp,\n",
    "            'humidity': humidity,\n",
    "            'pressure': pressure,\n",
    "            'wind_speed': wind_speed,\n",
    "            'heat_index': temp + 0.5 * humidity,\n",
    "            'pressure_anomaly': pressure - 1013\n",
    "        }\n",
    "        return features\n",
    "    \n",
    "    # Fazer previsÃµes para cada cenÃ¡rio\n",
    "    scenario_results = []\n",
    "    \n",
    "    for scenario_name, params in scenarios.items():\n",
    "        # Criar features\n",
    "        features = create_scenario_features(**params)\n",
    "        \n",
    "        # Criar array com as features na ordem correta\n",
    "        feature_values = [features[col] for col in available_features]\n",
    "        feature_array = np.array(feature_values).reshape(1, -1)\n",
    "        \n",
    "        # Fazer previsÃ£o\n",
    "        if best_model_name == 'Linear Regression':\n",
    "            feature_array = scaler.transform(feature_array)\n",
    "        \n",
    "        predicted_aqi = best_model.predict(feature_array)[0]\n",
    "        \n",
    "        # Determinar categoria de qualidade do ar\n",
    "        def get_aqi_category(aqi):\n",
    "            if aqi <= 50: return \"Boa\", \"green\"\n",
    "            elif aqi <= 100: return \"Moderada\", \"yellow\"\n",
    "            elif aqi <= 150: return \"Insalubre (Grupos SensÃ­veis)\", \"orange\"\n",
    "            elif aqi <= 200: return \"Insalubre\", \"red\"\n",
    "            elif aqi <= 300: return \"Muito Insalubre\", \"purple\"\n",
    "            else: return \"Perigosa\", \"maroon\"\n",
    "        \n",
    "        category, color = get_aqi_category(predicted_aqi)\n",
    "        \n",
    "        scenario_results.append({\n",
    "            'CenÃ¡rio': scenario_name,\n",
    "            'AQI Predito': predicted_aqi,\n",
    "            'Categoria': category,\n",
    "            'Temperatura': params['temperature'],\n",
    "            'Umidade': params['humidity'],\n",
    "            'PressÃ£o': params['pressure'],\n",
    "            'Vento': params['wind_speed']\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nğŸŒŸ {scenario_name}:\")\n",
    "        print(f\"   AQI Predito: {predicted_aqi:.1f} ({category})\")\n",
    "        print(f\"   CondiÃ§Ãµes: {params['temperature']}Â°C, {params['humidity']}% umidade, {params['wind_speed']} m/s vento\")\n",
    "    \n",
    "    # Criar DataFrame com resultados\n",
    "    scenario_df = pd.DataFrame(scenario_results)\n",
    "    \n",
    "    print(\"\\nğŸ“Š RESUMO DOS CENÃRIOS\")\n",
    "    print(\"=\" * 50)\n",
    "    display(scenario_df.round(1))\n",
    "    \n",
    "    # VisualizaÃ§Ã£o dos cenÃ¡rios\n",
    "    fig = px.bar(\n",
    "        scenario_df, \n",
    "        x='CenÃ¡rio', \n",
    "        y='AQI Predito',\n",
    "        color='Categoria',\n",
    "        title='PrevisÃ£o de AQI por CenÃ¡rio ClimÃ¡tico',\n",
    "        labels={'AQI Predito': 'Ãndice de Qualidade do Ar'},\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    # Adicionar linhas de referÃªncia para categorias\n",
    "    fig.add_hline(y=50, line_dash=\"dash\", line_color=\"green\", \n",
    "                  annotation_text=\"Limite Boa/Moderada\")\n",
    "    fig.add_hline(y=100, line_dash=\"dash\", line_color=\"orange\", \n",
    "                  annotation_text=\"Limite Moderada/Insalubre\")\n",
    "    fig.add_hline(y=150, line_dash=\"dash\", line_color=\"red\", \n",
    "                  annotation_text=\"Limite Insalubre\")\n",
    "    \n",
    "    fig.update_layout(xaxis_tickangle=-45)\n",
    "    fig.show()\n",
    "    \n",
    "    # AnÃ¡lise de sensibilidade\n",
    "    print(\"\\nğŸ” ANÃLISE DE SENSIBILIDADE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Testar como a temperatura afeta o AQI\n",
    "    base_scenario = scenarios['CondiÃ§Ãµes Ideais'].copy()\n",
    "    temp_range = np.arange(10, 45, 2)\n",
    "    temp_predictions = []\n",
    "    \n",
    "    for temp in temp_range:\n",
    "        test_scenario = base_scenario.copy()\n",
    "        test_scenario['temperature'] = temp\n",
    "        features = create_scenario_features(**test_scenario)\n",
    "        feature_values = [features[col] for col in available_features]\n",
    "        feature_array = np.array(feature_values).reshape(1, -1)\n",
    "        \n",
    "        if best_model_name == 'Linear Regression':\n",
    "            feature_array = scaler.transform(feature_array)\n",
    "        \n",
    "        pred_aqi = best_model.predict(feature_array)[0]\n",
    "        temp_predictions.append(pred_aqi)\n",
    "    \n",
    "    # Plotar sensibilidade Ã  temperatura\n",
    "    fig_sensitivity = go.Figure()\n",
    "    fig_sensitivity.add_trace(go.Scatter(\n",
    "        x=temp_range,\n",
    "        y=temp_predictions,\n",
    "        mode='lines+markers',\n",
    "        name='AQI vs Temperatura',\n",
    "        line=dict(color='red', width=3)\n",
    "    ))\n",
    "    \n",
    "    fig_sensitivity.update_layout(\n",
    "        title='Sensibilidade do AQI Ã  Temperatura',\n",
    "        xaxis_title='Temperatura (Â°C)',\n",
    "        yaxis_title='AQI Predito',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig_sensitivity.show()\n",
    "    \n",
    "    print(f\"ğŸ“ˆ O AQI varia de {min(temp_predictions):.1f} a {max(temp_predictions):.1f} \"\n",
    "          f\"quando a temperatura varia de {temp_range[0]}Â°C a {temp_range[-1]}Â°C\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ NÃ£o foi possÃ­vel fazer previsÃµes devido Ã  falta de modelo treinado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f853343",
   "metadata": {},
   "source": [
    "## ğŸ“‹ ConclusÃµes e Insights\n",
    "\n",
    "### ğŸ¯ Principais Descobertas\n",
    "\n",
    "1. **Modelagem Preditiva**: Conseguimos desenvolver modelos capazes de prever a qualidade do ar baseado em condiÃ§Ãµes meteorolÃ³gicas\n",
    "2. **Fatores Influentes**: Temperatura, umidade e velocidade do vento sÃ£o fatores crÃ­ticos para a qualidade do ar\n",
    "3. **PadrÃµes Sazonais**: Identificamos variaÃ§Ãµes significativas na qualidade do ar conforme as estaÃ§Ãµes\n",
    "\n",
    "### ğŸš€ PrÃ³ximos Passos\n",
    "\n",
    "1. **Coleta de Dados Reais**: Implementar coleta automatizada de dados via APIs\n",
    "2. **Modelos AvanÃ§ados**: Experimentar com redes neurais e modelos de sÃ©ries temporais\n",
    "3. **Alertas Inteligentes**: Desenvolver sistema de alertas baseado nas previsÃµes\n",
    "4. **Dashboard Interativo**: Expandir o dashboard Streamlit com essas anÃ¡lises\n",
    "\n",
    "### ğŸŒ Impacto Social\n",
    "\n",
    "Este projeto pode contribuir para:\n",
    "- **ConscientizaÃ§Ã£o ambiental** atravÃ©s de visualizaÃ§Ãµes claras\n",
    "- **Tomada de decisÃµes** baseada em dados cientÃ­ficos\n",
    "- **ProteÃ§Ã£o da saÃºde pÃºblica** com alertas antecipados\n",
    "- **Pesquisa climÃ¡tica** com dados estruturados e modelos preditivos\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ’š Desenvolvido com paixÃ£o por um futuro mais sustentÃ¡vel**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
