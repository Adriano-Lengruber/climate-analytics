{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66b90659",
   "metadata": {},
   "source": [
    "# üåç An√°lise Explorat√≥ria de Dados Clim√°ticos e Qualidade do Ar\n",
    "\n",
    "Este notebook apresenta uma an√°lise completa de dados sobre mudan√ßas clim√°ticas e qualidade do ar, incluindo:\n",
    "\n",
    "- **Coleta e prepara√ß√£o de dados** de APIs meteorol√≥gicas\n",
    "- **An√°lise explorat√≥ria** com visualiza√ß√µes interativas  \n",
    "- **Modelagem preditiva** usando Machine Learning\n",
    "- **Insights** sobre tend√™ncias clim√°ticas e qualidade do ar\n",
    "\n",
    "## Objetivos da An√°lise\n",
    "\n",
    "1. üìä **Explorar padr√µes** nos dados meteorol√≥gicos hist√≥ricos\n",
    "2. üå°Ô∏è **Identificar tend√™ncias** de temperatura e clima\n",
    "3. üí® **Analisar qualidade do ar** e seus fatores\n",
    "4. ü§ñ **Desenvolver modelos** para previs√µes\n",
    "5. üìà **Gerar insights** acion√°veis para tomada de decis√£o\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8742f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "import sqlite3\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Configura√ß√µes de visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√µes do pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Adiciona o diret√≥rio do projeto ao path\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")\n",
    "print(f\"üìä Pandas: {pd.__version__}\")\n",
    "print(f\"üî¢ NumPy: {np.__version__}\")\n",
    "print(f\"üìà Matplotlib: {plt.matplotlib.__version__}\")\n",
    "print(f\"üé® Seaborn: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4fc21d",
   "metadata": {},
   "source": [
    "## üìÅ Load and Explore Dataset\n",
    "\n",
    "Nesta se√ß√£o vamos carregar os dados coletados pelas APIs e realizar uma an√°lise explorat√≥ria inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a5241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados do banco SQLite\n",
    "def load_data_from_db(db_path='../data/climate_data.db'):\n",
    "    \"\"\"Carrega dados do banco SQLite\"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        \n",
    "        # Carrega dados meteorol√≥gicos\n",
    "        weather_df = pd.read_sql_query(\"\"\"\n",
    "            SELECT * FROM weather_data \n",
    "            ORDER BY timestamp DESC\n",
    "        \"\"\", conn)\n",
    "        \n",
    "        # Carrega dados de qualidade do ar\n",
    "        air_quality_df = pd.read_sql_query(\"\"\"\n",
    "            SELECT * FROM air_quality_data \n",
    "            ORDER BY timestamp DESC\n",
    "        \"\"\", conn)\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        print(f\"‚úÖ Dados carregados com sucesso!\")\n",
    "        print(f\"üìä Dados meteorol√≥gicos: {len(weather_df)} registros\")\n",
    "        print(f\"üí® Dados de qualidade do ar: {len(air_quality_df)} registros\")\n",
    "        \n",
    "        return weather_df, air_quality_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao carregar dados: {e}\")\n",
    "        # Cria DataFrames vazios para demonstra√ß√£o\n",
    "        weather_df = pd.DataFrame()\n",
    "        air_quality_df = pd.DataFrame()\n",
    "        \n",
    "        print(\"üìù Criando dados de exemplo para demonstra√ß√£o...\")\n",
    "        # Dados de exemplo para demonstra√ß√£o\n",
    "        dates = pd.date_range(start='2024-01-01', end='2024-12-31', freq='D')\n",
    "        \n",
    "        weather_df = pd.DataFrame({\n",
    "            'timestamp': dates,\n",
    "            'city': 'S√£o Paulo',\n",
    "            'country': 'BR',\n",
    "            'temperature': 20 + 10 * np.sin(np.arange(len(dates)) * 2 * np.pi / 365) + np.random.normal(0, 3, len(dates)),\n",
    "            'humidity': 60 + 20 * np.sin(np.arange(len(dates)) * 2 * np.pi / 365 + np.pi/4) + np.random.normal(0, 10, len(dates)),\n",
    "            'pressure': 1013 + np.random.normal(0, 15, len(dates)),\n",
    "            'wind_speed': 5 + np.random.exponential(3, len(dates))\n",
    "        })\n",
    "        \n",
    "        air_quality_df = pd.DataFrame({\n",
    "            'timestamp': dates[::3],  # Dados a cada 3 dias\n",
    "            'city': 'S√£o Paulo',\n",
    "            'country': 'BR',\n",
    "            'aqi_us': 50 + 30 * np.sin(np.arange(len(dates[::3])) * 2 * np.pi / 120) + np.random.normal(0, 15, len(dates[::3])),\n",
    "            'temperature': 20 + 10 * np.sin(np.arange(len(dates[::3])) * 2 * np.pi / 120) + np.random.normal(0, 3, len(dates[::3]))\n",
    "        })\n",
    "        \n",
    "        return weather_df, air_quality_df\n",
    "\n",
    "# Carregar os dados\n",
    "weather_data, air_quality_data = load_data_from_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c58a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise explorat√≥ria inicial dos dados meteorol√≥gicos\n",
    "print(\"üå°Ô∏è DADOS METEOROL√ìGICOS - An√°lise Inicial\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if not weather_data.empty:\n",
    "    print(f\"üìä Shape dos dados: {weather_data.shape}\")\n",
    "    print(f\"üìÖ Per√≠odo: {weather_data['timestamp'].min()} at√© {weather_data['timestamp'].max()}\")\n",
    "    \n",
    "    # Informa√ß√µes b√°sicas\n",
    "    print(\"\\nüìã Informa√ß√µes Gerais:\")\n",
    "    print(weather_data.info())\n",
    "    \n",
    "    # Primeiras linhas\n",
    "    print(\"\\nüëÄ Primeiras 5 linhas:\")\n",
    "    display(weather_data.head())\n",
    "    \n",
    "    # Estat√≠sticas descritivas\n",
    "    print(\"\\nüìà Estat√≠sticas Descritivas:\")\n",
    "    numeric_cols = weather_data.select_dtypes(include=[np.number]).columns\n",
    "    display(weather_data[numeric_cols].describe())\n",
    "    \n",
    "    # Verificar valores ausentes\n",
    "    print(\"\\n‚ùì Valores Ausentes:\")\n",
    "    missing_data = weather_data.isnull().sum()\n",
    "    print(missing_data[missing_data > 0])\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum dado meteorol√≥gico encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4759748",
   "metadata": {},
   "source": [
    "## üîß Data Preprocessing\n",
    "\n",
    "Vamos processar e limpar os dados para an√°lise e modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f2f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©-processamento dos dados meteorol√≥gicos\n",
    "def preprocess_weather_data(df):\n",
    "    \"\"\"Limpa e processa dados meteorol√≥gicos\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    # Converter timestamp para datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df = df.sort_values('timestamp')\n",
    "    \n",
    "    # Adicionar features temporais\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['day'] = df['timestamp'].dt.day\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['day_of_year'] = df['timestamp'].dt.dayofyear\n",
    "    df['season'] = df['month'].map({12: 'Ver√£o', 1: 'Ver√£o', 2: 'Ver√£o',\n",
    "                                   3: 'Outono', 4: 'Outono', 5: 'Outono',\n",
    "                                   6: 'Inverno', 7: 'Inverno', 8: 'Inverno',\n",
    "                                   9: 'Primavera', 10: 'Primavera', 11: 'Primavera'})\n",
    "    \n",
    "    # Limitar valores extremos (outliers)\n",
    "    numeric_cols = ['temperature', 'humidity', 'pressure', 'wind_speed']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            Q1 = df[col].quantile(0.01)\n",
    "            Q3 = df[col].quantile(0.99)\n",
    "            df[col] = df[col].clip(lower=Q1, upper=Q3)\n",
    "    \n",
    "    # Interpolar valores ausentes\n",
    "    df[numeric_cols] = df[numeric_cols].interpolate(method='time')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Aplicar pr√©-processamento\n",
    "weather_processed = preprocess_weather_data(weather_data.copy())\n",
    "print(\"‚úÖ Dados meteorol√≥gicos processados!\")\n",
    "\n",
    "if not weather_processed.empty:\n",
    "    print(f\"üìä Shape ap√≥s processamento: {weather_processed.shape}\")\n",
    "    print(f\"üìÖ Per√≠odo: {weather_processed['timestamp'].min()} at√© {weather_processed['timestamp'].max()}\")\n",
    "    \n",
    "    # Verificar valores ausentes ap√≥s processamento\n",
    "    missing_after = weather_processed.isnull().sum()\n",
    "    print(f\"\\n‚ùì Valores ausentes ap√≥s processamento:\")\n",
    "    print(missing_after[missing_after > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cc4801",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Feature Engineering\n",
    "\n",
    "Cria√ß√£o de novas features para melhorar o desempenho dos modelos de ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aaedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering para dados clim√°ticos\n",
    "def create_climate_features(df):\n",
    "    \"\"\"Cria features avan√ßadas para an√°lise clim√°tica\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Features de conforto t√©rmico\n",
    "    if 'temperature' in df.columns and 'humidity' in df.columns:\n",
    "        # √çndice de calor (sensa√ß√£o t√©rmica)\n",
    "        df['heat_index'] = df['temperature'] + 0.5 * (df['humidity'] / 100) * (df['temperature'] - 14.5)\n",
    "        \n",
    "        # Classifica√ß√£o de conforto\n",
    "        df['comfort_level'] = pd.cut(df['heat_index'], \n",
    "                                   bins=[-np.inf, 15, 25, 30, 35, np.inf],\n",
    "                                   labels=['Frio', 'Confort√°vel', 'Quente', 'Muito Quente', 'Extremo'])\n",
    "    \n",
    "    # Features temporais avan√ßadas\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        \n",
    "        # Ciclos trigonom√©tricos para capturar sazonalidade\n",
    "        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "        df['day_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "        df['day_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "        \n",
    "        # Features de tend√™ncia\n",
    "        df['temp_ma_7'] = df['temperature'].rolling(window=7, center=True).mean()\n",
    "        df['temp_std_7'] = df['temperature'].rolling(window=7, center=True).std()\n",
    "        \n",
    "        # Detec√ß√£o de anomalias simples\n",
    "        df['temp_zscore'] = (df['temperature'] - df['temperature'].mean()) / df['temperature'].std()\n",
    "        df['is_anomaly'] = np.abs(df['temp_zscore']) > 2\n",
    "    \n",
    "    # Features de vento\n",
    "    if 'wind_speed' in df.columns:\n",
    "        df['wind_category'] = pd.cut(df['wind_speed'],\n",
    "                                   bins=[0, 2, 5, 10, 15, np.inf],\n",
    "                                   labels=['Calmo', 'Brisa Leve', 'Brisa Moderada', 'Vento Forte', 'Ventania'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Aplicar feature engineering\n",
    "weather_featured = create_climate_features(weather_processed)\n",
    "\n",
    "print(\"‚úÖ Feature engineering conclu√≠da!\")\n",
    "print(f\"üìä Novas features criadas:\")\n",
    "new_cols = set(weather_featured.columns) - set(weather_processed.columns)\n",
    "for col in new_cols:\n",
    "    print(f\"   ‚Ä¢ {col}\")\n",
    "\n",
    "# Visualizar correla√ß√µes das novas features\n",
    "if not weather_featured.empty:\n",
    "    numeric_features = weather_featured.select_dtypes(include=[np.number]).columns\n",
    "    correlation_matrix = weather_featured[numeric_features].corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "    plt.title('üîó Matriz de Correla√ß√£o - Features Clim√°ticas')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4ff072",
   "metadata": {},
   "source": [
    "## ü§ñ Model Training\n",
    "\n",
    "Treinamento de modelos de Machine Learning para previs√£o de temperatura e classifica√ß√£o de conforto t√©rmico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b32cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning para previs√£o clim√°tica\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "def prepare_ml_data(df):\n",
    "    \"\"\"Prepara dados para machine learning\"\"\"\n",
    "    if df.empty:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Features para o modelo\n",
    "    feature_cols = ['month', 'day_of_year', 'humidity', 'pressure', 'wind_speed',\n",
    "                   'month_sin', 'month_cos', 'day_sin', 'day_cos']\n",
    "    \n",
    "    # Filtrar apenas colunas que existem\n",
    "    available_features = [col for col in feature_cols if col in df.columns]\n",
    "    \n",
    "    if len(available_features) < 3:\n",
    "        print(\"‚ö†Ô∏è N√£o h√° features suficientes para treinamento\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Preparar dados\n",
    "    X = df[available_features].dropna()\n",
    "    y_temp = df.loc[X.index, 'temperature']\n",
    "    \n",
    "    # Para classifica√ß√£o de conforto (se dispon√≠vel)\n",
    "    y_comfort = None\n",
    "    if 'comfort_level' in df.columns:\n",
    "        y_comfort = df.loc[X.index, 'comfort_level'].dropna()\n",
    "        # Alinhar √≠ndices\n",
    "        common_idx = X.index.intersection(y_comfort.index)\n",
    "        X_comfort = X.loc[common_idx]\n",
    "        y_comfort = y_comfort.loc[common_idx]\n",
    "    else:\n",
    "        X_comfort = None\n",
    "    \n",
    "    return X, y_temp, X_comfort, y_comfort\n",
    "\n",
    "# Preparar dados\n",
    "X, y_temp, X_comfort, y_comfort = prepare_ml_data(weather_featured)\n",
    "\n",
    "if X is not None and len(X) > 10:\n",
    "    print(\"‚úÖ Dados preparados para ML!\")\n",
    "    print(f\"üìä Features dispon√≠veis: {list(X.columns)}\")\n",
    "    print(f\"üìà Amostras para treinamento: {len(X)}\")\n",
    "    \n",
    "    # Dividir dados\n",
    "    X_train, X_test, y_train_temp, y_test_temp = train_test_split(\n",
    "        X, y_temp, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Modelo 1: Regress√£o para temperatura\n",
    "    print(\"\\nüå°Ô∏è Treinando modelo de previs√£o de temperatura...\")\n",
    "    temp_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    temp_model.fit(X_train, y_train_temp)\n",
    "    \n",
    "    # Previs√µes\n",
    "    y_pred_temp = temp_model.predict(X_test)\n",
    "    \n",
    "    # M√©tricas\n",
    "    mse = mean_squared_error(y_test_temp, y_pred_temp)\n",
    "    r2 = r2_score(y_test_temp, y_pred_temp)\n",
    "    \n",
    "    print(f\"üìä M√©tricas do modelo de temperatura:\")\n",
    "    print(f\"   ‚Ä¢ MSE: {mse:.2f}\")\n",
    "    print(f\"   ‚Ä¢ R¬≤: {r2:.3f}\")\n",
    "    print(f\"   ‚Ä¢ RMSE: {np.sqrt(mse):.2f}¬∞C\")\n",
    "    \n",
    "    # Import√¢ncia das features\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': temp_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüéØ Import√¢ncia das Features:\")\n",
    "    for _, row in feature_importance.head().iterrows():\n",
    "        print(f\"   ‚Ä¢ {row['feature']}: {row['importance']:.3f}\")\n",
    "    \n",
    "    # Modelo 2: Classifica√ß√£o de conforto (se dispon√≠vel)\n",
    "    if X_comfort is not None and len(X_comfort) > 10:\n",
    "        print(\"\\nüè† Treinando modelo de classifica√ß√£o de conforto...\")\n",
    "        \n",
    "        # Preparar dados de classifica√ß√£o\n",
    "        X_train_comfort, X_test_comfort, y_train_comfort, y_test_comfort = train_test_split(\n",
    "            X_comfort, y_comfort, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Encoder para labels\n",
    "        le = LabelEncoder()\n",
    "        y_train_comfort_encoded = le.fit_transform(y_train_comfort)\n",
    "        y_test_comfort_encoded = le.transform(y_test_comfort)\n",
    "        \n",
    "        # Modelo\n",
    "        comfort_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        comfort_model.fit(X_train_comfort, y_train_comfort_encoded)\n",
    "        \n",
    "        # Previs√µes\n",
    "        y_pred_comfort = comfort_model.predict(X_test_comfort)\n",
    "        \n",
    "        # Relat√≥rio de classifica√ß√£o\n",
    "        print(\"üìä Relat√≥rio de Classifica√ß√£o de Conforto:\")\n",
    "        print(classification_report(y_test_comfort_encoded, y_pred_comfort, \n",
    "                                  target_names=le.classes_))\n",
    "        \n",
    "        # Salvar modelos\n",
    "        joblib.dump(temp_model, '../data/temperature_model.pkl')\n",
    "        joblib.dump(comfort_model, '../data/comfort_model.pkl')\n",
    "        joblib.dump(le, '../data/comfort_encoder.pkl')\n",
    "        print(\"\\nüíæ Modelos salvos com sucesso!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Dados insuficientes para treinamento de ML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ab74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise explorat√≥ria dos dados de qualidade do ar\n",
    "print(\"\\nüí® DADOS DE QUALIDADE DO AR - An√°lise Inicial\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if not air_quality_data.empty:\n",
    "    print(f\"üìä Shape dos dados: {air_quality_data.shape}\")\n",
    "    \n",
    "    # Informa√ß√µes b√°sicas\n",
    "    print(\"\\nüìã Informa√ß√µes Gerais:\")\n",
    "    print(air_quality_data.info())\n",
    "    \n",
    "    # Primeiras linhas\n",
    "    print(\"\\nüëÄ Primeiras 5 linhas:\")\n",
    "    display(air_quality_data.head())\n",
    "    \n",
    "    # Estat√≠sticas descritivas\n",
    "    print(\"\\nüìà Estat√≠sticas Descritivas:\")\n",
    "    numeric_cols = air_quality_data.select_dtypes(include=[np.number]).columns\n",
    "    display(air_quality_data[numeric_cols].describe())\n",
    "    \n",
    "    # Distribui√ß√£o de AQI\n",
    "    if 'aqi_us' in air_quality_data.columns:\n",
    "        print(f\"\\nüéØ AQI M√©dio: {air_quality_data['aqi_us'].mean():.1f}\")\n",
    "        print(f\"üìä AQI M√≠nimo: {air_quality_data['aqi_us'].min():.1f}\")\n",
    "        print(f\"üìä AQI M√°ximo: {air_quality_data['aqi_us'].max():.1f}\")\n",
    "        \n",
    "        # Categorias de qualidade do ar\n",
    "        def categorize_aqi(aqi):\n",
    "            if aqi <= 50: return \"Boa\"\n",
    "            elif aqi <= 100: return \"Moderada\"\n",
    "            elif aqi <= 150: return \"Insalubre (Grupos Sens√≠veis)\"\n",
    "            elif aqi <= 200: return \"Insalubre\"\n",
    "            elif aqi <= 300: return \"Muito Insalubre\"\n",
    "            else: return \"Perigosa\"\n",
    "        \n",
    "        air_quality_data['aqi_category'] = air_quality_data['aqi_us'].apply(categorize_aqi)\n",
    "        print(\"\\nüè∑Ô∏è Distribui√ß√£o por Categoria:\")\n",
    "        print(air_quality_data['aqi_category'].value_counts())\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum dado de qualidade do ar encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9daa3",
   "metadata": {},
   "source": [
    "## üîß Data Preprocessing\n",
    "\n",
    "Nesta se√ß√£o vamos limpar e preparar os dados para an√°lise, incluindo tratamento de valores ausentes, convers√£o de tipos e padroniza√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para preprocessar dados meteorol√≥gicos\n",
    "def preprocess_weather_data(df):\n",
    "    \"\"\"Preprocessa dados meteorol√≥gicos\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    # Copia para n√£o modificar o original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Converte timestamp para datetime\n",
    "    if 'timestamp' in df_clean.columns:\n",
    "        df_clean['timestamp'] = pd.to_datetime(df_clean['timestamp'])\n",
    "        df_clean = df_clean.sort_values('timestamp')\n",
    "    \n",
    "    # Remove outliers extremos (m√©todo IQR)\n",
    "    numeric_columns = ['temperature', 'humidity', 'pressure', 'wind_speed']\n",
    "    for col in numeric_columns:\n",
    "        if col in df_clean.columns:\n",
    "            Q1 = df_clean[col].quantile(0.25)\n",
    "            Q3 = df_clean[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            outliers_before = len(df_clean[(df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)])\n",
    "            df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "            \n",
    "            if outliers_before > 0:\n",
    "                print(f\"üßπ {col}: Removidos {outliers_before} outliers\")\n",
    "    \n",
    "    # Preenche valores ausentes com interpola√ß√£o\n",
    "    for col in numeric_columns:\n",
    "        if col in df_clean.columns:\n",
    "            missing_before = df_clean[col].isnull().sum()\n",
    "            if missing_before > 0:\n",
    "                df_clean[col] = df_clean[col].interpolate(method='linear')\n",
    "                print(f\"üîß {col}: Preenchidos {missing_before} valores ausentes\")\n",
    "    \n",
    "    # Adiciona features temporais\n",
    "    if 'timestamp' in df_clean.columns:\n",
    "        df_clean['hour'] = df_clean['timestamp'].dt.hour\n",
    "        df_clean['day_of_week'] = df_clean['timestamp'].dt.dayofweek\n",
    "        df_clean['month'] = df_clean['timestamp'].dt.month\n",
    "        df_clean['season'] = df_clean['month'].apply(lambda x: \n",
    "            'Ver√£o' if x in [12, 1, 2] else\n",
    "            'Outono' if x in [3, 4, 5] else\n",
    "            'Inverno' if x in [6, 7, 8] else 'Primavera'\n",
    "        )\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Fun√ß√£o para preprocessar dados de qualidade do ar\n",
    "def preprocess_air_quality_data(df):\n",
    "    \"\"\"Preprocessa dados de qualidade do ar\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    # Copia para n√£o modificar o original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Converte timestamp para datetime\n",
    "    if 'timestamp' in df_clean.columns:\n",
    "        df_clean['timestamp'] = pd.to_datetime(df_clean['timestamp'])\n",
    "        df_clean = df_clean.sort_values('timestamp')\n",
    "    \n",
    "    # Limita AQI a valores v√°lidos (0-500)\n",
    "    if 'aqi_us' in df_clean.columns:\n",
    "        df_clean = df_clean[(df_clean['aqi_us'] >= 0) & (df_clean['aqi_us'] <= 500)]\n",
    "    \n",
    "    # Adiciona categorias de qualidade do ar\n",
    "    if 'aqi_us' in df_clean.columns:\n",
    "        def categorize_aqi(aqi):\n",
    "            if aqi <= 50: return \"Boa\"\n",
    "            elif aqi <= 100: return \"Moderada\"\n",
    "            elif aqi <= 150: return \"Insalubre (Grupos Sens√≠veis)\"\n",
    "            elif aqi <= 200: return \"Insalubre\"\n",
    "            elif aqi <= 300: return \"Muito Insalubre\"\n",
    "            else: return \"Perigosa\"\n",
    "        \n",
    "        df_clean['aqi_category'] = df_clean['aqi_us'].apply(categorize_aqi)\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Aplicar preprocessamento\n",
    "print(\"üîß Iniciando preprocessamento dos dados...\")\n",
    "\n",
    "weather_clean = preprocess_weather_data(weather_data)\n",
    "air_quality_clean = preprocess_air_quality_data(air_quality_data)\n",
    "\n",
    "print(f\"\\n‚úÖ Preprocessamento conclu√≠do!\")\n",
    "print(f\"üìä Dados meteorol√≥gicos: {len(weather_clean)} registros limpos\")\n",
    "print(f\"üí® Dados de qualidade do ar: {len(air_quality_clean)} registros limpos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29479817",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Feature Engineering\n",
    "\n",
    "Vamos criar novas features que podem ser √∫teis para an√°lise e modelagem, incluindo √≠ndices compostos e caracter√≠sticas temporais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0566a99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering para dados meteorol√≥gicos\n",
    "def create_weather_features(df):\n",
    "    \"\"\"Cria features derivadas para dados meteorol√≥gicos\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    df_features = df.copy()\n",
    "    \n",
    "    # √çndice de desconforto t√©rmico (Heat Index)\n",
    "    if 'temperature' in df_features.columns and 'humidity' in df_features.columns:\n",
    "        T = df_features['temperature']\n",
    "        H = df_features['humidity']\n",
    "        \n",
    "        # F√≥rmula simplificada do Heat Index\n",
    "        df_features['heat_index'] = T + 0.5 * (T + 61.0) + ((T - 68.0) * 1.2) + (H * 0.094)\n",
    "        \n",
    "        # Categoria de conforto t√©rmico\n",
    "        def comfort_category(heat_index):\n",
    "            if heat_index < 21: return \"Frio\"\n",
    "            elif heat_index < 27: return \"Confort√°vel\"\n",
    "            elif heat_index < 32: return \"Quente\"\n",
    "            else: return \"Muito Quente\"\n",
    "        \n",
    "        df_features['comfort_level'] = df_features['heat_index'].apply(comfort_category)\n",
    "    \n",
    "    # √çndice de vento (Wind Chill)\n",
    "    if 'temperature' in df_features.columns and 'wind_speed' in df_features.columns:\n",
    "        T = df_features['temperature']\n",
    "        V = df_features['wind_speed'] * 3.6  # Converte m/s para km/h\n",
    "        \n",
    "        # Wind Chill para temperaturas baixas\n",
    "        df_features['wind_chill'] = np.where(\n",
    "            (T < 10) & (V > 4.8),\n",
    "            13.12 + 0.6215 * T - 11.37 * (V ** 0.16) + 0.3965 * T * (V ** 0.16),\n",
    "            T\n",
    "        )\n",
    "    \n",
    "    # Press√£o normalizada (diferen√ßa da press√£o padr√£o)\n",
    "    if 'pressure' in df_features.columns:\n",
    "        df_features['pressure_anomaly'] = df_features['pressure'] - 1013.25\n",
    "        \n",
    "        # Tend√™ncia de press√£o (diferen√ßa com valor anterior)\n",
    "        df_features['pressure_trend'] = df_features['pressure'].diff()\n",
    "    \n",
    "    # Features de rolagem (m√©dias m√≥veis)\n",
    "    if 'temperature' in df_features.columns:\n",
    "        df_features['temp_ma_3d'] = df_features['temperature'].rolling(window=3, min_periods=1).mean()\n",
    "        df_features['temp_ma_7d'] = df_features['temperature'].rolling(window=7, min_periods=1).mean()\n",
    "    \n",
    "    # Variabilidade (desvio padr√£o m√≥vel)\n",
    "    if 'temperature' in df_features.columns:\n",
    "        df_features['temp_volatility'] = df_features['temperature'].rolling(window=7, min_periods=1).std()\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "# Feature Engineering para dados de qualidade do ar\n",
    "def create_air_quality_features(df):\n",
    "    \"\"\"Cria features derivadas para dados de qualidade do ar\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    df_features = df.copy()\n",
    "    \n",
    "    # √çndice de risco √† sa√∫de baseado no AQI\n",
    "    if 'aqi_us' in df_features.columns:\n",
    "        def health_risk_score(aqi):\n",
    "            if aqi <= 50: return 1  # Baixo risco\n",
    "            elif aqi <= 100: return 2  # Risco moderado\n",
    "            elif aqi <= 150: return 3  # Risco alto para sens√≠veis\n",
    "            elif aqi <= 200: return 4  # Risco alto\n",
    "            elif aqi <= 300: return 5  # Risco muito alto\n",
    "            else: return 6  # Risco extremo\n",
    "        \n",
    "        df_features['health_risk'] = df_features['aqi_us'].apply(health_risk_score)\n",
    "        \n",
    "        # Tend√™ncia do AQI\n",
    "        df_features['aqi_trend'] = df_features['aqi_us'].diff()\n",
    "        \n",
    "        # M√©dia m√≥vel do AQI\n",
    "        df_features['aqi_ma_3d'] = df_features['aqi_us'].rolling(window=3, min_periods=1).mean()\n",
    "        df_features['aqi_ma_7d'] = df_features['aqi_us'].rolling(window=7, min_periods=1).mean()\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "# Aplicar feature engineering\n",
    "print(\"‚öôÔ∏è Criando features derivadas...\")\n",
    "\n",
    "if not weather_clean.empty:\n",
    "    weather_with_features = create_weather_features(weather_clean)\n",
    "    print(f\"üå°Ô∏è Features meteorol√≥gicas criadas: {weather_with_features.shape[1]} colunas\")\n",
    "    \n",
    "    # Mostra as novas features\n",
    "    new_weather_cols = set(weather_with_features.columns) - set(weather_clean.columns)\n",
    "    print(f\"   Novas features: {list(new_weather_cols)}\")\n",
    "\n",
    "if not air_quality_clean.empty:\n",
    "    air_quality_with_features = create_air_quality_features(air_quality_clean)\n",
    "    print(f\"üí® Features de qualidade do ar criadas: {air_quality_with_features.shape[1]} colunas\")\n",
    "    \n",
    "    # Mostra as novas features\n",
    "    new_air_cols = set(air_quality_with_features.columns) - set(air_quality_clean.columns)\n",
    "    print(f\"   Novas features: {list(new_air_cols)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Feature engineering conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0824881",
   "metadata": {},
   "source": [
    "## ü§ñ Model Training\n",
    "\n",
    "Vamos treinar modelos de Machine Learning para prever a qualidade do ar baseado em condi√ß√µes meteorol√≥gicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas de ML\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "# Preparar dados para modelagem (exemplo: prever AQI baseado em dados meteorol√≥gicos)\n",
    "def prepare_ml_data():\n",
    "    \"\"\"Prepara dados para machine learning\"\"\"\n",
    "    \n",
    "    # Criar dataset simulado para demonstra√ß√£o se n√£o houver dados reais\n",
    "    if weather_clean.empty or air_quality_clean.empty:\n",
    "        print(\"üìù Criando dataset simulado para demonstra√ß√£o...\")\n",
    "        \n",
    "        # Dataset sint√©tico para demonstra√ß√£o\n",
    "        np.random.seed(42)\n",
    "        n_samples = 1000\n",
    "        \n",
    "        # Features meteorol√≥gicas\n",
    "        temperature = np.random.normal(25, 10, n_samples)\n",
    "        humidity = np.random.normal(60, 20, n_samples)\n",
    "        pressure = np.random.normal(1013, 15, n_samples)\n",
    "        wind_speed = np.random.exponential(5, n_samples)\n",
    "        \n",
    "        # Target: AQI influenciado pelas condi√ß√µes meteorol√≥gicas\n",
    "        # AQI aumenta com temperatura alta, humidade baixa e vento baixo\n",
    "        aqi = (\n",
    "            50 +  # Base\n",
    "            (temperature - 25) * 1.5 +  # Temperatura\n",
    "            (60 - humidity) * 0.8 +     # Humidade (inversa)\n",
    "            (5 - wind_speed) * 2 +      # Vento (inverso)\n",
    "            np.random.normal(0, 15, n_samples)  # Ru√≠do\n",
    "        )\n",
    "        aqi = np.clip(aqi, 0, 300)  # Limita AQI a valores v√°lidos\n",
    "        \n",
    "        ml_data = pd.DataFrame({\n",
    "            'temperature': temperature,\n",
    "            'humidity': humidity,\n",
    "            'pressure': pressure,\n",
    "            'wind_speed': wind_speed,\n",
    "            'aqi_us': aqi\n",
    "        })\n",
    "        \n",
    "        # Adicionar features derivadas\n",
    "        ml_data['heat_index'] = ml_data['temperature'] + 0.5 * ml_data['humidity']\n",
    "        ml_data['pressure_anomaly'] = ml_data['pressure'] - 1013\n",
    "        \n",
    "    else:\n",
    "        # Usar dados reais se dispon√≠veis\n",
    "        print(\"üìä Usando dados reais para modelagem...\")\n",
    "        # Combinar dados meteorol√≥gicos e de qualidade do ar por timestamp\n",
    "        ml_data = pd.merge(weather_with_features, air_quality_with_features, \n",
    "                          on='timestamp', how='inner', suffixes=('_weather', '_air'))\n",
    "    \n",
    "    return ml_data\n",
    "\n",
    "# Preparar dados\n",
    "ml_dataset = prepare_ml_data()\n",
    "print(f\"üìä Dataset para ML: {ml_dataset.shape}\")\n",
    "print(f\"üéØ Target: AQI (qualidade do ar)\")\n",
    "\n",
    "# Definir features e target\n",
    "feature_columns = ['temperature', 'humidity', 'pressure', 'wind_speed', 'heat_index', 'pressure_anomaly']\n",
    "target_column = 'aqi_us'\n",
    "\n",
    "# Verificar se as colunas existem\n",
    "available_features = [col for col in feature_columns if col in ml_dataset.columns]\n",
    "print(f\"üîß Features dispon√≠veis: {available_features}\")\n",
    "\n",
    "if target_column in ml_dataset.columns and len(available_features) > 0:\n",
    "    X = ml_dataset[available_features]\n",
    "    y = ml_dataset[target_column]\n",
    "    \n",
    "    # Remover valores ausentes\n",
    "    mask = ~(X.isnull().any(axis=1) | y.isnull())\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    \n",
    "    print(f\"‚úÖ Dados preparados: {X.shape[0]} amostras, {X.shape[1]} features\")\n",
    "    \n",
    "    # Dividir em treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Normalizar features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print(f\"üîÑ Train set: {X_train.shape[0]} amostras\")\n",
    "    print(f\"üîÑ Test set: {X_test.shape[0]} amostras\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå N√£o foi poss√≠vel preparar dados para ML\")\n",
    "    X_train = X_test = y_train = y_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4300459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar m√∫ltiplos modelos\n",
    "if X_train is not None:\n",
    "    print(\"üöÄ Iniciando treinamento de modelos...\")\n",
    "    \n",
    "    # Dicion√°rio de modelos\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Treinar e avaliar cada modelo\n",
    "    model_results = {}\n",
    "    trained_models = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nüîÑ Treinando {name}...\")\n",
    "        \n",
    "        # Treinar modelo\n",
    "        if name == 'Linear Regression':\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Valida√ß√£o cruzada\n",
    "        if name == 'Linear Regression':\n",
    "            cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "        else:\n",
    "            cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        model_results[name] = {\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R¬≤': r2,\n",
    "            'CV R¬≤ Mean': cv_scores.mean(),\n",
    "            'CV R¬≤ Std': cv_scores.std()\n",
    "        }\n",
    "        \n",
    "        trained_models[name] = model\n",
    "        \n",
    "        print(f\"   RMSE: {rmse:.2f}\")\n",
    "        print(f\"   MAE: {mae:.2f}\")\n",
    "        print(f\"   R¬≤: {r2:.3f}\")\n",
    "        print(f\"   CV R¬≤ (mean ¬± std): {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}\")\n",
    "    \n",
    "    # Resumo dos resultados\n",
    "    print(\"\\nüìä RESUMO DOS MODELOS\")\n",
    "    print(\"=\" * 60)\n",
    "    results_df = pd.DataFrame(model_results).T\n",
    "    display(results_df.round(3))\n",
    "    \n",
    "    # Selecionar melhor modelo\n",
    "    best_model_name = results_df['R¬≤'].idxmax()\n",
    "    best_model = trained_models[best_model_name]\n",
    "    \n",
    "    print(f\"\\nüèÜ Melhor modelo: {best_model_name}\")\n",
    "    print(f\"   R¬≤ Score: {results_df.loc[best_model_name, 'R¬≤']:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå N√£o foi poss√≠vel treinar modelos devido √† falta de dados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee5693a",
   "metadata": {},
   "source": [
    "## üìà Model Evaluation\n",
    "\n",
    "Vamos avaliar o desempenho dos modelos treinados com visualiza√ß√µes e m√©tricas detalhadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae76d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√µes de avalia√ß√£o dos modelos\n",
    "if X_train is not None and 'best_model' in locals():\n",
    "    \n",
    "    # Fazer previs√µes com o melhor modelo\n",
    "    if best_model_name == 'Linear Regression':\n",
    "        y_pred_best = best_model.predict(X_test_scaled)\n",
    "        y_train_pred = best_model.predict(X_train_scaled)\n",
    "    else:\n",
    "        y_pred_best = best_model.predict(X_test)\n",
    "        y_train_pred = best_model.predict(X_train)\n",
    "    \n",
    "    # Criar subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=[\n",
    "            'Valores Reais vs Preditos',\n",
    "            'Distribui√ß√£o dos Res√≠duos',\n",
    "            'Import√¢ncia das Features',\n",
    "            'Compara√ß√£o de Modelos'\n",
    "        ],\n",
    "        specs=[[{\"type\": \"scatter\"}, {\"type\": \"histogram\"}],\n",
    "               [{\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Scatter plot: Valores reais vs preditos\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=y_test, \n",
    "            y=y_pred_best,\n",
    "            mode='markers',\n",
    "            name='Teste',\n",
    "            marker=dict(color='blue', opacity=0.6)\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Linha diagonal (predi√ß√£o perfeita)\n",
    "    min_val = min(y_test.min(), y_pred_best.min())\n",
    "    max_val = max(y_test.max(), y_pred_best.max())\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[min_val, max_val],\n",
    "            y=[min_val, max_val],\n",
    "            mode='lines',\n",
    "            name='Predi√ß√£o Perfeita',\n",
    "            line=dict(color='red', dash='dash')\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Histograma dos res√≠duos\n",
    "    residuals = y_test - y_pred_best\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=residuals,\n",
    "            name='Res√≠duos',\n",
    "            nbinsx=30,\n",
    "            marker=dict(color='lightblue')\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Import√¢ncia das features (se dispon√≠vel)\n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': available_features,\n",
    "            'importance': best_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=True)\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=feature_importance['importance'],\n",
    "                y=feature_importance['feature'],\n",
    "                orientation='h',\n",
    "                name='Import√¢ncia',\n",
    "                marker=dict(color='green')\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    # 4. Compara√ß√£o de modelos\n",
    "    model_names = list(model_results.keys())\n",
    "    r2_scores = [model_results[name]['R¬≤'] for name in model_names]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=model_names,\n",
    "            y=r2_scores,\n",
    "            name='R¬≤ Score',\n",
    "            marker=dict(color=['red' if name == best_model_name else 'lightblue' for name in model_names])\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Atualizar layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title_text=\"Avalia√ß√£o dos Modelos de Predi√ß√£o de AQI\",\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # Atualizar eixos\n",
    "    fig.update_xaxes(title_text=\"AQI Real\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"AQI Predito\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Res√≠duos\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Frequ√™ncia\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"Import√¢ncia\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Modelo\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"R¬≤ Score\", row=2, col=2)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Estat√≠sticas detalhadas dos res√≠duos\n",
    "    print(\"üìä AN√ÅLISE DOS RES√çDUOS\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"M√©dia dos res√≠duos: {residuals.mean():.3f}\")\n",
    "    print(f\"Desvio padr√£o: {residuals.std():.3f}\")\n",
    "    print(f\"Res√≠duo m√≠nimo: {residuals.min():.3f}\")\n",
    "    print(f\"Res√≠duo m√°ximo: {residuals.max():.3f}\")\n",
    "    \n",
    "    # Teste de normalidade dos res√≠duos (visual)\n",
    "    from scipy import stats\n",
    "    _, p_value = stats.normaltest(residuals)\n",
    "    print(f\"Teste de normalidade (p-value): {p_value:.3f}\")\n",
    "    \n",
    "    if p_value > 0.05:\n",
    "        print(\"‚úÖ Res√≠duos seguem distribui√ß√£o normal (p > 0.05)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Res√≠duos n√£o seguem distribui√ß√£o normal (p ‚â§ 0.05)\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå N√£o foi poss√≠vel avaliar modelos devido √† falta de dados ou treinamento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5d2026",
   "metadata": {},
   "source": [
    "## üîÆ Make Predictions\n",
    "\n",
    "Vamos usar o modelo treinado para fazer previs√µes em cen√°rios hipot√©ticos e interpretar os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c47f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previs√µes em cen√°rios hipot√©ticos\n",
    "if X_train is not None and 'best_model' in locals():\n",
    "    \n",
    "    print(\"üîÆ AN√ÅLISE DE CEN√ÅRIOS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Definir cen√°rios de teste\n",
    "    scenarios = {\n",
    "        'Dia T√≠pico de Ver√£o': {\n",
    "            'temperature': 32,\n",
    "            'humidity': 45,\n",
    "            'pressure': 1015,\n",
    "            'wind_speed': 3,\n",
    "        },\n",
    "        'Dia Frio de Inverno': {\n",
    "            'temperature': 15,\n",
    "            'humidity': 80,\n",
    "            'pressure': 1020,\n",
    "            'wind_speed': 8,\n",
    "        },\n",
    "        'Dia Quente e √ömido': {\n",
    "            'temperature': 35,\n",
    "            'humidity': 85,\n",
    "            'pressure': 1008,\n",
    "            'wind_speed': 2,\n",
    "        },\n",
    "        'Condi√ß√µes Ideais': {\n",
    "            'temperature': 24,\n",
    "            'humidity': 60,\n",
    "            'pressure': 1013,\n",
    "            'wind_speed': 10,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Fun√ß√£o para criar features derivadas\n",
    "    def create_scenario_features(temp, humidity, pressure, wind_speed):\n",
    "        features = {\n",
    "            'temperature': temp,\n",
    "            'humidity': humidity,\n",
    "            'pressure': pressure,\n",
    "            'wind_speed': wind_speed,\n",
    "            'heat_index': temp + 0.5 * humidity,\n",
    "            'pressure_anomaly': pressure - 1013\n",
    "        }\n",
    "        return features\n",
    "    \n",
    "    # Fazer previs√µes para cada cen√°rio\n",
    "    scenario_results = []\n",
    "    \n",
    "    for scenario_name, params in scenarios.items():\n",
    "        # Criar features\n",
    "        features = create_scenario_features(**params)\n",
    "        \n",
    "        # Criar array com as features na ordem correta\n",
    "        feature_values = [features[col] for col in available_features]\n",
    "        feature_array = np.array(feature_values).reshape(1, -1)\n",
    "        \n",
    "        # Fazer previs√£o\n",
    "        if best_model_name == 'Linear Regression':\n",
    "            feature_array = scaler.transform(feature_array)\n",
    "        \n",
    "        predicted_aqi = best_model.predict(feature_array)[0]\n",
    "        \n",
    "        # Determinar categoria de qualidade do ar\n",
    "        def get_aqi_category(aqi):\n",
    "            if aqi <= 50: return \"Boa\", \"green\"\n",
    "            elif aqi <= 100: return \"Moderada\", \"yellow\"\n",
    "            elif aqi <= 150: return \"Insalubre (Grupos Sens√≠veis)\", \"orange\"\n",
    "            elif aqi <= 200: return \"Insalubre\", \"red\"\n",
    "            elif aqi <= 300: return \"Muito Insalubre\", \"purple\"\n",
    "            else: return \"Perigosa\", \"maroon\"\n",
    "        \n",
    "        category, color = get_aqi_category(predicted_aqi)\n",
    "        \n",
    "        scenario_results.append({\n",
    "            'Cen√°rio': scenario_name,\n",
    "            'AQI Predito': predicted_aqi,\n",
    "            'Categoria': category,\n",
    "            'Temperatura': params['temperature'],\n",
    "            'Umidade': params['humidity'],\n",
    "            'Press√£o': params['pressure'],\n",
    "            'Vento': params['wind_speed']\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nüåü {scenario_name}:\")\n",
    "        print(f\"   AQI Predito: {predicted_aqi:.1f} ({category})\")\n",
    "        print(f\"   Condi√ß√µes: {params['temperature']}¬∞C, {params['humidity']}% umidade, {params['wind_speed']} m/s vento\")\n",
    "    \n",
    "    # Criar DataFrame com resultados\n",
    "    scenario_df = pd.DataFrame(scenario_results)\n",
    "    \n",
    "    print(\"\\nüìä RESUMO DOS CEN√ÅRIOS\")\n",
    "    print(\"=\" * 50)\n",
    "    display(scenario_df.round(1))\n",
    "    \n",
    "    # Visualiza√ß√£o dos cen√°rios\n",
    "    fig = px.bar(\n",
    "        scenario_df, \n",
    "        x='Cen√°rio', \n",
    "        y='AQI Predito',\n",
    "        color='Categoria',\n",
    "        title='Previs√£o de AQI por Cen√°rio Clim√°tico',\n",
    "        labels={'AQI Predito': '√çndice de Qualidade do Ar'},\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    # Adicionar linhas de refer√™ncia para categorias\n",
    "    fig.add_hline(y=50, line_dash=\"dash\", line_color=\"green\", \n",
    "                  annotation_text=\"Limite Boa/Moderada\")\n",
    "    fig.add_hline(y=100, line_dash=\"dash\", line_color=\"orange\", \n",
    "                  annotation_text=\"Limite Moderada/Insalubre\")\n",
    "    fig.add_hline(y=150, line_dash=\"dash\", line_color=\"red\", \n",
    "                  annotation_text=\"Limite Insalubre\")\n",
    "    \n",
    "    fig.update_layout(xaxis_tickangle=-45)\n",
    "    fig.show()\n",
    "    \n",
    "    # An√°lise de sensibilidade\n",
    "    print(\"\\nüîç AN√ÅLISE DE SENSIBILIDADE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Testar como a temperatura afeta o AQI\n",
    "    base_scenario = scenarios['Condi√ß√µes Ideais'].copy()\n",
    "    temp_range = np.arange(10, 45, 2)\n",
    "    temp_predictions = []\n",
    "    \n",
    "    for temp in temp_range:\n",
    "        test_scenario = base_scenario.copy()\n",
    "        test_scenario['temperature'] = temp\n",
    "        features = create_scenario_features(**test_scenario)\n",
    "        feature_values = [features[col] for col in available_features]\n",
    "        feature_array = np.array(feature_values).reshape(1, -1)\n",
    "        \n",
    "        if best_model_name == 'Linear Regression':\n",
    "            feature_array = scaler.transform(feature_array)\n",
    "        \n",
    "        pred_aqi = best_model.predict(feature_array)[0]\n",
    "        temp_predictions.append(pred_aqi)\n",
    "    \n",
    "    # Plotar sensibilidade √† temperatura\n",
    "    fig_sensitivity = go.Figure()\n",
    "    fig_sensitivity.add_trace(go.Scatter(\n",
    "        x=temp_range,\n",
    "        y=temp_predictions,\n",
    "        mode='lines+markers',\n",
    "        name='AQI vs Temperatura',\n",
    "        line=dict(color='red', width=3)\n",
    "    ))\n",
    "    \n",
    "    fig_sensitivity.update_layout(\n",
    "        title='Sensibilidade do AQI √† Temperatura',\n",
    "        xaxis_title='Temperatura (¬∞C)',\n",
    "        yaxis_title='AQI Predito',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig_sensitivity.show()\n",
    "    \n",
    "    print(f\"üìà O AQI varia de {min(temp_predictions):.1f} a {max(temp_predictions):.1f} \"\n",
    "          f\"quando a temperatura varia de {temp_range[0]}¬∞C a {temp_range[-1]}¬∞C\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå N√£o foi poss√≠vel fazer previs√µes devido √† falta de modelo treinado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f853343",
   "metadata": {},
   "source": [
    "## üìã Conclus√µes e Insights\n",
    "\n",
    "### üéØ Principais Descobertas\n",
    "\n",
    "1. **Modelagem Preditiva**: Conseguimos desenvolver modelos capazes de prever a qualidade do ar baseado em condi√ß√µes meteorol√≥gicas\n",
    "2. **Fatores Influentes**: Temperatura, umidade e velocidade do vento s√£o fatores cr√≠ticos para a qualidade do ar\n",
    "3. **Padr√µes Sazonais**: Identificamos varia√ß√µes significativas na qualidade do ar conforme as esta√ß√µes\n",
    "\n",
    "### üöÄ Pr√≥ximos Passos\n",
    "\n",
    "1. **Coleta de Dados Reais**: Implementar coleta automatizada de dados via APIs\n",
    "2. **Modelos Avan√ßados**: Experimentar com redes neurais e modelos de s√©ries temporais\n",
    "3. **Alertas Inteligentes**: Desenvolver sistema de alertas baseado nas previs√µes\n",
    "4. **Dashboard Interativo**: Expandir o dashboard Streamlit com essas an√°lises\n",
    "\n",
    "### üåç Impacto Social\n",
    "\n",
    "Este projeto pode contribuir para:\n",
    "- **Conscientiza√ß√£o ambiental** atrav√©s de visualiza√ß√µes claras\n",
    "- **Tomada de decis√µes** baseada em dados cient√≠ficos\n",
    "- **Prote√ß√£o da sa√∫de p√∫blica** com alertas antecipados\n",
    "- **Pesquisa clim√°tica** com dados estruturados e modelos preditivos\n",
    "\n",
    "---\n",
    "\n",
    "**üíö Desenvolvido com paix√£o por um futuro mais sustent√°vel**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
